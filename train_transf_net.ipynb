{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow==4.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.6MB 5.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: olefile in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pillow==4.0.0) (0.45.1)\n",
      "Installing collected packages: pillow\n",
      "  Found existing installation: Pillow 5.2.0\n",
      "    Uninstalling Pillow-5.2.0:\n",
      "      Successfully uninstalled Pillow-5.2.0\n",
      "Successfully installed pillow-4.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 30.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Downgrade pillow to avoid `UserWarning: Possibly corrupt EXIF data.`\n",
    "!pip install pillow==4.0.0\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 74488\n",
      "drwxrwxr-x 14 ec2-user ec2-user     4096 Dec 17 12:38 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x  5 ec2-user ec2-user     4096 Dec 17 12:22 \u001b[01;34m..\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData\u001b[0m/\n",
      "drwxrwxr-x  4 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mDatabase\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_equalized\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_partial_excluded\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_Suspect\u001b[0m/\n",
      "drwxrwxr-x  8 ec2-user ec2-user     4096 Dec 16 20:21 \u001b[01;34mefficientnet_keras_transfer_learning\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1487 Dec 13 01:48 evaluation_test.py\n",
      "drwxrwxr-x  8 ec2-user ec2-user     4096 Dec 17 12:38 \u001b[01;34m.git\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1212 Dec 13 01:48 .gitignore\n",
      "-rw-rw-r--  1 ec2-user ec2-user     4859 Dec 13 01:48 Graphs.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    14282 Dec 17 12:36 Interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    11233 Dec 13 02:25 Interpreter.pyc\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 19:09 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user    80428 Dec 13 01:48 \u001b[01;35mmodel1_accuracy_128.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    79404 Dec 13 01:48 \u001b[01;35mmodel1_accuracy_64.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    55417 Dec 16 17:33 \u001b[01;35mmodel1_accuracy.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    95680 Dec 13 01:48 \u001b[01;35mmodel1_loss_128.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    82434 Dec 13 01:48 \u001b[01;35mmodel1_loss_64.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    53318 Dec 16 17:33 \u001b[01;35mmodel1_loss.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user 43972720 Dec 13 01:48 model.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1786368 Dec 13 01:48 model_simple_128.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     5509 Dec 13 01:48 model_simple_128.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user  3354720 Dec 13 01:48 model_simple_64.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     4568 Dec 13 01:48 model_simple_64.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user 26406864 Dec 13 01:48 model_simple.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     6065 Dec 13 01:48 model_simple.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1302 Dec 13 01:48 pre_proc.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mProcessing\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     5092 Dec 13 01:48 Processor.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 16 20:49 \u001b[01;34m__pycache__\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1926 Dec 13 01:48 README.md\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mreferences\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user      211 Dec 13 01:48 requirements.txt\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1314 Dec 13 01:48 test_interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user     3009 Dec 13 01:48 test_processor.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    23987 Dec 16 17:33 train_model.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1213 Dec 16 17:33 train_start.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    13298 Dec 17 12:38 train_transf_net.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user    81132 Dec 13 19:09 Untitled.ipynb\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:52 \u001b[01;34mWindowOpt\u001b[0m/\n",
      "[Errno 2] No such file or directory: 'eye-Image-Analysis/'\n",
      "/home/ec2-user/SageMaker/eye-Image-Analysis\n",
      "total 74488\n",
      "drwxrwxr-x 14 ec2-user ec2-user     4096 Dec 17 12:38 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x  5 ec2-user ec2-user     4096 Dec 17 12:22 \u001b[01;34m..\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData\u001b[0m/\n",
      "drwxrwxr-x  4 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mDatabase\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_equalized\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_partial_excluded\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mData_Suspect\u001b[0m/\n",
      "drwxrwxr-x  8 ec2-user ec2-user     4096 Dec 16 20:21 \u001b[01;34mefficientnet_keras_transfer_learning\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1487 Dec 13 01:48 evaluation_test.py\n",
      "drwxrwxr-x  8 ec2-user ec2-user     4096 Dec 17 12:38 \u001b[01;34m.git\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1212 Dec 13 01:48 .gitignore\n",
      "-rw-rw-r--  1 ec2-user ec2-user     4859 Dec 13 01:48 Graphs.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    14282 Dec 17 12:36 Interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    11233 Dec 13 02:25 Interpreter.pyc\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 19:09 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user    80428 Dec 13 01:48 \u001b[01;35mmodel1_accuracy_128.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    79404 Dec 13 01:48 \u001b[01;35mmodel1_accuracy_64.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    55417 Dec 16 17:33 \u001b[01;35mmodel1_accuracy.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    95680 Dec 13 01:48 \u001b[01;35mmodel1_loss_128.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    82434 Dec 13 01:48 \u001b[01;35mmodel1_loss_64.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user    53318 Dec 16 17:33 \u001b[01;35mmodel1_loss.png\u001b[0m\n",
      "-rw-rw-r--  1 ec2-user ec2-user 43972720 Dec 13 01:48 model.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1786368 Dec 13 01:48 model_simple_128.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     5509 Dec 13 01:48 model_simple_128.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user  3354720 Dec 13 01:48 model_simple_64.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     4568 Dec 13 01:48 model_simple_64.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user 26406864 Dec 13 01:48 model_simple.h5\n",
      "-rw-rw-r--  1 ec2-user ec2-user     6065 Dec 13 01:48 model_simple.json\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1302 Dec 13 01:48 pre_proc.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mProcessing\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     5092 Dec 13 01:48 Processor.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 16 20:49 \u001b[01;34m__pycache__\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1926 Dec 13 01:48 README.md\n",
      "drwxrwxr-x  2 ec2-user ec2-user     4096 Dec 13 01:48 \u001b[01;34mreferences\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user      211 Dec 13 01:48 requirements.txt\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1314 Dec 13 01:48 test_interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user     3009 Dec 13 01:48 test_processor.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    23987 Dec 16 17:33 train_model.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user     1213 Dec 16 17:33 train_start.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user    13298 Dec 17 12:38 train_transf_net.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user    81132 Dec 13 19:09 Untitled.ipynb\n",
      "drwxrwxr-x  3 ec2-user ec2-user     4096 Dec 13 01:52 \u001b[01;34mWindowOpt\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls -la\n",
    "%cd eye-Image-Analysis/\n",
    "%ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Interpreter import Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 706 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n",
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "\n",
    "inter = Interpreter(\n",
    "    BATCH_SIZE,\n",
    "    IMAGE_SHAPE,\n",
    "    EPOCHS,\n",
    "    TARGET_SIZE\n",
    ")\n",
    "\n",
    "train_images, validation_images, test_images = inter.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/eye-Image-Analysis/efficientnet_keras_transfer_learning/efficientnet/layers.py:30: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
      "16719872/16717576 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Model)      (None, 8, 8, 1280)        4049564   \n",
      "_________________________________________________________________\n",
      "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_out (Dropout)        (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "fc_out (Dense)               (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n",
      "This is the number of trainable layers before freezing the conv base: 213\n",
      "This is the number of trainable layers after freezing the conv base: 2\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 445, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n",
      "    interpolation=self.interpolation)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\", line 132, in load_img\n",
      "    img = img.resize(width_height_tuple, resample)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\", line 1541, in resize\n",
      "    self.load()\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/PIL/ImageFile.py\", line 207, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-45321b5f0276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalidation_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/SageMaker/eye-Image-Analysis/Interpreter.py\u001b[0m in \u001b[0;36mtrain_efficient_net\u001b[0;34m(self, train_images, test_images, validation_images)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m         session != self._session):\n\u001b[0;32m-> 3073\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, model_out = inter.train_efficient_net(\n",
    "    train_images,\n",
    "    test_images,\n",
    "    validation_images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
