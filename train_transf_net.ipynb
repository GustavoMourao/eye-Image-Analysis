{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow==4.0.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (4.0.0)\n",
      "Requirement already satisfied: olefile in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pillow==4.0.0) (0.45.1)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (1.14.3)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Downgrade pillow to avoid `UserWarning: Possibly corrupt EXIF data.`\n",
    "!pip install pillow==4.0.0\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 256\n",
      "drwxrwxr-x 15 ec2-user ec2-user  4096 Dec 17 13:21 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x  5 ec2-user ec2-user  4096 Dec 17 13:01 \u001b[01;34m..\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData\u001b[0m/\n",
      "drwxrwxr-x  4 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mDatabase\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_equalized\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_partial_excluded\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_Suspect\u001b[0m/\n",
      "drwxrwxr-x  8 ec2-user ec2-user  4096 Dec 16 20:21 \u001b[01;34mefficientnet_keras_transfer_learning\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1487 Dec 13 01:48 evaluation_test.py\n",
      "drwxrwxr-x  8 ec2-user ec2-user  4096 Dec 17 13:31 \u001b[01;34m.git\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1212 Dec 13 01:48 .gitignore\n",
      "-rw-rw-r--  1 ec2-user ec2-user  4859 Dec 13 01:48 Graphs.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 15831 Dec 17 13:13 Interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 11233 Dec 13 02:25 Interpreter.pyc\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:10 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:09 \u001b[01;34mModels\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1302 Dec 13 01:48 pre_proc.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mProcessing\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  5092 Dec 13 01:48 Processor.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:04 \u001b[01;34m__pycache__\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1926 Dec 13 01:48 README.md\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mreferences\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user   231 Dec 17 13:10 requirements.txt\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1314 Dec 13 01:48 test_interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user  3009 Dec 13 01:48 test_processor.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 23987 Dec 16 17:33 train_model.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1213 Dec 16 17:33 train_start.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 12720 Dec 17 13:21 train_transf_net.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user 81132 Dec 13 19:09 Untitled.ipynb\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:52 \u001b[01;34mWindowOpt\u001b[0m/\n",
      "[Errno 2] No such file or directory: 'eye-Image-Analysis/'\n",
      "/home/ec2-user/SageMaker/eye-Image-Analysis\n",
      "total 256\n",
      "drwxrwxr-x 15 ec2-user ec2-user  4096 Dec 17 13:21 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x  5 ec2-user ec2-user  4096 Dec 17 13:01 \u001b[01;34m..\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData\u001b[0m/\n",
      "drwxrwxr-x  4 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mDatabase\u001b[0m/\n",
      "drwxrwxr-x  5 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_equalized\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_partial_excluded\u001b[0m/\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mData_Suspect\u001b[0m/\n",
      "drwxrwxr-x  8 ec2-user ec2-user  4096 Dec 16 20:21 \u001b[01;34mefficientnet_keras_transfer_learning\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1487 Dec 13 01:48 evaluation_test.py\n",
      "drwxrwxr-x  8 ec2-user ec2-user  4096 Dec 17 13:31 \u001b[01;34m.git\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1212 Dec 13 01:48 .gitignore\n",
      "-rw-rw-r--  1 ec2-user ec2-user  4859 Dec 13 01:48 Graphs.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 15831 Dec 17 13:13 Interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 11233 Dec 13 02:25 Interpreter.pyc\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:10 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:09 \u001b[01;34mModels\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1302 Dec 13 01:48 pre_proc.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mProcessing\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  5092 Dec 13 01:48 Processor.py\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 17 13:04 \u001b[01;34m__pycache__\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1926 Dec 13 01:48 README.md\n",
      "drwxrwxr-x  2 ec2-user ec2-user  4096 Dec 13 01:48 \u001b[01;34mreferences\u001b[0m/\n",
      "-rw-rw-r--  1 ec2-user ec2-user   231 Dec 17 13:10 requirements.txt\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1314 Dec 13 01:48 test_interpreter.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user  3009 Dec 13 01:48 test_processor.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 23987 Dec 16 17:33 train_model.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user  1213 Dec 16 17:33 train_start.py\n",
      "-rw-rw-r--  1 ec2-user ec2-user 12720 Dec 17 13:21 train_transf_net.ipynb\n",
      "-rw-rw-r--  1 ec2-user ec2-user 81132 Dec 13 19:09 Untitled.ipynb\n",
      "drwxrwxr-x  3 ec2-user ec2-user  4096 Dec 13 01:52 \u001b[01;34mWindowOpt\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls -la\n",
    "%cd eye-Image-Analysis/\n",
    "%ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Interpreter import Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "IMAGE_SHAPE = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 706 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n",
      "Found 94 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "inter = Interpreter(\n",
    "    BATCH_SIZE,\n",
    "    IMAGE_SHAPE,\n",
    "    EPOCHS,\n",
    "    TARGET_SIZE\n",
    ")\n",
    "\n",
    "train_images, validation_images, test_images = inter.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b0 (Model)      (None, 8, 8, 1280)        4049564   \n",
      "_________________________________________________________________\n",
      "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_out (Dropout)        (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "fc_out (Dense)               (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n",
      "This is the number of trainable layers before freezing the conv base: 213\n",
      "This is the number of trainable layers after freezing the conv base: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-85:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 619, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 600, in pool_fn\n",
      "    workers, initializer=init_pool_generator, initargs=(seqs, None))\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "model, model_out = inter.train_efficient_net(\n",
    "    train_images,\n",
    "    test_images,\n",
    "    validation_images,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_out = inter.train_efficient_net(\n",
    "    train_images,\n",
    "    test_images,\n",
    "    validation_images,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Train EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_out = inter.train_efficient_net(\n",
    "    train_images,\n",
    "    test_images,\n",
    "    validation_images,\n",
    "    2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
